---
title: 主流深度学习框架
date: 2018-03-13 16:09:38
tags: [深度学习]
categories: [机器学习]
---

# 主流深度学习框架

深度学习研究的热潮持续高涨，各种开源深度学习框架也层出不穷，其中包括**TensorFlow、Caffe、Keras、CNTK、Torch7、MXNet、Leaf、Theano、DeepLearning4、Lasagne、Neon**，等等

![各个开源框架在GitHub上的数据统计](/images/机器学习主流框架.png)

![主流深度学习框架在各个维度的评分](/images/主流深度学习框架在各个维度的评分.png)

TensorFlow比如设计神经网络结构的代码的简洁度，分布式深度学习算法的执行效率，还有部署的便利性。

# TensorFlow

TensorFlow是**相对高阶的机器学习库**，用户可以方便地用它设计神经网络结构，而不必为了追求高效率的实现亲自写C++或CUDA代码。

核心代码和Caffe一样是用**C++**编写的，使用C++简化了线上部署的复杂度，并让手机这种内存和CPU资源都紧张的设备可以运行复杂模型（Python则会比较消耗资源，并且执行效率不高）。除了核心代码的C++接口，TensorFlow还有官方的Python、Go和Java接口，是通过SWIG（Simplified Wrapper and Interface Generator）实现的，这样用户就可以在一个硬件配置较好的机器中用Python进行实验，并在资源比较紧张的嵌入式环境或需要低延迟的环境中用C++部署模型。

- 特点
	- **支持多种机器学习算法**。同时TensorFlow不只局限于神经网络，其数据流式图支持非常自由的算法表达，当然也可以轻松实现深度学习以外的机器学习算法。

	- **支持数据并行模式**。

	- **灵活的移植性，部署便利性** 。可以将同一份代码几乎不经过修改就轻松地部署到有任意数量CPU或GPU的PC、服务器或者移动设备上。相比于Theano，TensorFlow还有一个优势就是它极快的编译速度，在定义新网络结构时，Theano通常需要长时间的编译，因此尝试新模型需要比较大的代价，而TensorFlow完全没有这个问题。

	- **可视化组件**。TensorFlow还有功能强大的可视化组件TensorBoard，能可视化网络结构和训练过程，对于观察复杂的网络结构和监控长时间、大规模的训练很有帮助。TensorFlow针对生产环境高度优化，它产品级的高质量代码和设计都可以保证在生产环境中稳定运行，同时一旦TensorFlow广泛地被工业界使用，将产生良性循环，成为深度学习领域的事实标准。
	
# [Caffe](caffe.berkeleyvision.org/)
 
Caffe全称为Convolutional Architecture for Fast Feature Embedding，是一个被广泛使用的开源深度学习框架（在TensorFlow出现之前一直是深度学习领域GitHub star最多的项目），目前由伯克利视觉学中心（Berkeley Vision and Learning Center，BVLC）进行维护。Caffe的创始人是加州大学伯克利的Ph.D.贾扬清，他同时也是TensorFlow的作者之一，曾工作于MSRA、NEC和Google Brain，目前就职于Facebook FAIR实验室。[caffe_GitHub](GitHub：github.com/BVLC/caffe)

- Caffe的主要优势包括如下几点:
	- **容易上手**，网络结构都是以配置文件形式定义，不需要用代码设计网络。
	- **训练速度快**，能够训练state-of-the-art的模型与大规模的数据。
	- **组件模块化**，可以方便地拓展到新的模型和学习任务上。

# [Theano](http://www.deeplearning.net/software/theano/)

Theano诞生于2008年，由蒙特利尔大学Lisa Lab团队开发并维护，是一个高性能的符号计算及深度学习库。因其出现时间早，可以算是这类库的始祖之一，也一度被认为是深度学习研究和应用的重要标准之一。Theano的核心是一个数学表达式的编译器，专门为处理大规模神经网络训练的计算而设计。它可以将用户定义的各种计算编译为高效的底层代码，并链接各种可以加速的库，比如BLAS、CUDA等。Theano允许用户定义、优化和评估包含多维数组的数学表达式，它支持将计算装载到GPU（Theano在GPU上性能不错，但是CPU上较差）。与Scikit-learn一样，Theano也很好地整合了NumPy，对GPU的透明让Theano可以较为方便地进行神经网络设计，而不必直接写CUDA代码。[theano_github](github.com/Theano/Theano)

- Theano的主要优势如下:

- **集成NumPy**，可以直接使用NumPy的ndarray，API接口学习成本低。
- **计算稳定性好**，比如可以精准地计算输出值很小的函数（像log(1+x)）。
- **动态地生成C或者CUDA代码**，用以编译成高效的机器代码。

> Theano是一个完全基于Python（C++/CUDA代码也是打包为Python字符串）的符号计算库

# [Keras](keras.io)

Keras是一个**崇尚极简、高度模块化的神经网络库**，使用**Python**实现，并可以同时运行在TensorFlow和Theano上。它旨在让用户进行最快速的原型实验，让想法变为结果的这个过程最短。Theano和TensorFlow的计算图支持更通用的计算，而**Keras则专精于深度学习**。Theano和TensorFlow更像是深度学习领域的NumPy，而Keras则是这个领域的Scikit-learn。它提供了目前为止最方便的API，用户只需要将高级的模块拼在一起，就可以设计神经网络，它大大降低了编程开销（code overhead）和阅读别人代码时的理解开销（cognitive overhead）。它同时支持卷积网络和循环网络，支持级联的模型或任意的图结构的模型（可以让某些数据跳过某些Layer和后面的Layer对接，使得创建Inception等复杂网络变得容易），从CPU上计算切换到GPU加速无须任何代码的改动。因为底层使用Theano或TensorFlow，用Keras训练模型相比于前两者基本没有什么性能损耗（还可以享受前两者持续开发带来的性能提升），只是简化了编程的复杂度，节约了尝试新网络结构的时间。可以说模型越复杂，使用Keras的收益就越大，尤其是在高度依赖权值共享、多模型组合、多任务学习等模型上，Keras表现得非常突出。Keras所有的模块都是简洁、易懂、完全可配置、可随意插拔的，并且基本上没有任何使用限制，神经网络、损失函数、优化器、初始化方法、激活函数和正则化等模块都是可以自由组合的。Keras也包括绝大部分state-of-the-art的Trick，包括Adam、RMSProp、Batch Normalization、PReLU、ELU、LeakyReLU等。同时，新的模块也很容易添加，这让Keras非常适合最前沿的研究。Keras中的模型也都是在Python中定义的，不像Caffe、CNTK等需要额外的文件来定义模型，这样就可以通过编程的方式调试模型结构和各种超参数。在Keras中，只需要几行代码就能实现一个MLP，或者十几行代码实现一个AlexNet，这在其他深度学习框架中基本是不可能完成的任务。Keras最大的问题可能是目前无法直接使用多GPU，所以对大规模的数据处理速度没有其他支持多GPU和分布式的框架快。Keras的编程模型设计和Torch很像，但是相比Torch，Keras构建在Python上，有一套完整的科学计算工具链，而Torch的编程语言Lua并没有这样一条科学计算工具链。无论从社区人数，还是活跃度来看，Keras目前的增长速度都已经远远超过了Torch。[keras_github](github.com/fchollet/keras)


# [Torch](http://torch.ch/ )

Torch给自己的定位是LuaJIT上的一个高效的科学计算库，支持大量的机器学习算法，同时以GPU上的计算优先。Torch的历史非常悠久，但真正得到发扬光大是在Facebook开源了其深度学习的组件之后，此后包括Google、Twitter、NYU、IDIAP、Purdue等组织都大量使用Torch。Torch的目标是让设计科学计算算法变得便捷，它包含了大量的机器学习、计算机视觉、信号处理、并行运算、图像、视频、音频、网络处理的库，同时和Caffe类似，Torch拥有大量的训练好的深度学习模型。它可以支持设计非常复杂的神经网络的拓扑图结构，再并行化到CPU和GPU上，在Torch上设计新的Layer是相对简单的。它和TensorFlow一样使用了底层C++加上层脚本语言调用的方式，只不过Torch使用的是Lua。Lua的性能是非常优秀的（该语言经常被用来开发游戏），常见的代码可以通过透明的JIT优化达到C的性能的80%；在便利性上，Lua的语法也非常简单易读，拥有漂亮和统一的结构，易于掌握，比写C/C++简洁很多；同时，Lua拥有一个非常直接的调用C程序的接口，可以简便地使用大量基于C的库，因为底层核心是C写的，因此也可以方便地移植到各种环境。Lua支持Linux、Mac，还支持各种嵌入式系统（iOS、Android、FPGA等），只不过运行时还是必须有LuaJIT的环境，所以工业生产环境的使用相对较少，没有Caffe和TensorFlow那么多。
[torch_github](github.com/torch/torch7)




参考资料：
1. [主流深度学习框架对比](http://blog.csdn.net/zuochao_2013/article/details/56024172)
2. [现在最火的深度学习框架是什么？_2017](https://www.zhihu.com/question/52517062)