---
title: 应用监督式学习
date: 2018-03-16 13:55:38
tags: [监督学习]
categories: [机器学习]
---

# 监督学习

**定义**：监督式学习算法接受已知的输入数据集合（训练集）和已知的对数据的响应（输出），然后训练一个模型，为新输入数据的响应生成合理的预测。**监督学习技术可分成分类或者回归**的形式。

- **分类**：技术预测**离散**的响应。例如，电子邮件是真正邮件还是垃圾邮件，肿瘤是小块、中等还是大块。分类模型经过训练后，将数据划分成类别。应用软件包括医学成像、语音识别和信用评分。分类问题分为：

	- **二元分类问题**，单个训练或测试项目（实例）只能分成两类。例如，如果您想确定电子邮件是真正邮件，还是垃圾邮件。
	- **多类分类问题**，可以分成多个类。例如，如果您想训练一个模型，将图像分类为狗、猫或其它动物。
	
	> 多类分类问题一般更具挑战性，因为需要比较复杂的模型。

- **回归**：预测**连续**的响应。例如，电力需求中温度或波动的变化。应用软件包括预测股价、笔迹识别和声信号处理。

----------

# 分类算法

## 逻辑回归

- **工作原理**：适合可以预测属于一个类或另一个类的二元响应概率的模型。因为逻辑回归比较简单，所以常用作二分类问题的起点。

- **适用场景**：
	- 当数据能由一个线性边界清晰划分时
	- 作为评估更复杂分类方法的基准

- **示意图**：

	![线性回归](/images/线性回归.jpg)

## k最近邻(kNN)

- **工作原理**:kNN 根据数据集内类的最近邻关系划分对象的类别。kNN预测假定相互靠近的对象是相似的。距离量度（如欧氏距离、绝对值距离、夹角余弦和 Chebychev 距离）用来查找最近邻。

- **适用场景**：当您需要简单算法来设立基准学习规则时
	- 当无需太关注 训练模型的内存使用时
	- 当无需太关注 训练模型的预测速度时

## 支持向量机 (SVM)

- **工作原理**：通过搜索能将全部数据点分割开的判别边界（超平面）对数据进行分类。当数据为线性可分离时，SVM 的最佳超平面是在两个类之间具有最大边距的超平面。如果数据不是线性可分离，则使用损失函数对处于超平面错误一边的点进行惩罚。SVM 有时使用核变换，将非线性可分离的数据变换为可找到线性判定边界的更高维度。

- **适用场景**：
	- 适用于正好有两个类的数据（借助所谓的纠错输出码技术，也可以将其用于多类分类）
	- 适用于高维、非线性可分离的数据
	- 当您需要一个简单、易于解释、准确的分类器时


## 神经网络

- **工作原理**：受人脑的启发，神经网络由高度互连的神经元网络组成，这些神经元将输入与所需输出相关联。通过反复修改联系的强度，对网络进行训练，使给定的输入映射到正确的响应。

- **适用场景**：
	- 适用于高度非线性系统建模
	- 当数据逐渐增多，而您希望不断更新模型时
	- 当您的输入数据可能有意外变动时
	- 当模型可解释性不是主要考虑因素时


## 朴素贝叶斯

- **工作原理**：朴素贝叶斯分类器假设类中某一具体特征的存在与任何其他特征的存在不相关。根据数据属于某个特定类的最高概率对新数据进行分类。

- **适用场景**：
	- 适用于包含许多参数的小数据集
	- 当您需要易于解释的分类器时
	- 当模型会遇到不在训练数据中的情形时，许多金融和医学应用就属于这种情况

- 示意图

## 判别分析

- **工作原理**：判别分析通过发现特征的线性组合来对数据分类。判别分析假定不同的类根据高斯分布生成数据。训练判别分析模型涉及查找每个类的高斯分布的参数。分布参数用来计算边界，边界可能为线性函数或二次函数。这些边界用来确定新数据的类。

- **适用场景**：
	- 当需要易于解释的简单模型时
	- 当训练过程中的内存使用是需要关注的问题时
	- 当您需要快速预测的模型时


## 决策树

- **工作原理**：利用决策树预测对数据响应的方法是，按照树中根节点（起始）到叶节点的顺序自上而下地决策。树由分支条件组成，在这些条件中，预测元的值与训练的权重进行比较。分支的数量和权重的值在训练过程中确定。附加修改或剪枝可用来简化模型。

- **适用场景**：
	- 当需要易于解释和快速拟合的算法时
	- 最小化内存使用
	- 当不要求很高的预测准确性时

## Bagged和Boosted决策树

- **工作原理**：在这些集成方法中，几个“较弱”的决策树组合成一个“较强”的整体。
	- **袋装决策树**由根据从输入数据中自举的数据进行独立训练的树组成。
	- **促进决策树**涉及创建一个强学习器，具体方法是，迭代地添加“弱”
	学习器并调节每个弱学习器的权重，从而将重点放在错误分类的
	样本

- **适用场景**：
	- 当预测元为无序类别（离散）或表现非线性时
	- 当无需太关注训练一个模型所用时间时

----------

# 回归算法
## 线性回归
- **工作原理**：线性回归是一项统计建模技术，用来描述作为一个或多个预测元变量的线性函数的连续应变量。因为线性回归模型解释简单，易于训练，所以通常是第一个要与新数据集拟合的模型。

- **适用场景**：
	- 当需要易于解释和快速拟合的算法时
	- 作为评估其他更复杂回归模型的基准

## 非线性回归
- **工作原理**：非线性回归是一种有助于描述实验数据中非线性关系的统计建模技术。通常将非线性回归模型假设为参数模型，将该模型称为非线性方程。“非线性”是指一个拟合函数，它是多个参数的非线性函数。例如，如果拟合参数为b0、b1和b2：方程式`y = b0+b1x+b2x2`是拟合参数的线性函数，而 `y = (b`0xb1)/(x+b2) 是拟合参数的非线性函数。
- **适用场景**：
	- 当数据有很强的非线性趋势，不容易转化成线性空间时
	- 适用于自定义模型与数据拟合


## 高斯过程回归模型
- **工作原理**：高斯过程回归 (GPR) 模型是非参数模型，用于预测连续应变量的值。这些模型广泛用于对存在不确定情况下的插值进行空间分析的领域。 GPR 也称为克里格法 (Kriging)。
- **适用场景**：
	- 适用于对空间数据插值，如针对地下水分布水文地质学数据
	- 作为有助于优化汽车发动机等复杂设计的替代模型

## SVM 回归
- **工作原理**：SVM 回归算法类似于 SVM 分类算法，但经过改良，能够预测连续响应。不同于查找一个分离数据的超平面， SVM 回归算法查找一个偏离测量数据的模型，偏离的值不大于一个小数额，采用尽可能小的参数值（使对误差的敏感度最小）。
- **适用场景**：适用于高维数据（将会有大量的预测元变量）


## 广义线性回归
- **工作原理**：广义线性模型是使用线性方法的非线性模型的一种特殊情况。它涉及输入的线性组合与输出的非线性函数（连接函数）拟合。
- **适用场景**：当应变量有非正态分布时，比如始终预期为正值的应变量

## 回归树
- **工作原理**：回归的决策树类似于分类的决策树，但经过改良，能够预测连续响应。
- **适用场景**：当预测元为无序类别（离散）或表现非线性时
