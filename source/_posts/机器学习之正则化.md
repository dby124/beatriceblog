---
title: 机器学习之正则化
date: 2017-10-17 15:47:53
tags: [正则化]
categories: [机器学习]
---

根据上一篇博客《[统计学习概论](http://dingby.site/2017/09/11/34%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/)》可以知道，正则化的作用是**选择经验风险和模型复杂度同时较小的模型**。下面从过拟合的角度来理解正则化。

#过拟合问题

例子说明，线性回归问题（房价）

![example_of_overfitting](/images/example_of_overfitting.png)

- 分析：

	1）左边第一幅图，图中获得拟合模型是这样一条直线，但是，实际上这并不是一个很好的模型。这些数据明显表明，随着房子面积增大，住房价格的变化趋于稳定或者说越往右越平缓。因此线性回归并没有很好拟合训练数据。这种情况称为**欠拟合（underfitting）**，或者叫做**高偏差（high bias）**。这两种叫法大致相似，都表示没有很好地拟合训练数据。

	2）第二幅图，中间加入一个二次项，也就是说数据使用二次函数去拟合。拟合出曲线的拟合效果很好。

	3）在第三幅图中对于该数据集用一个四次多项式来拟合。因此在这里我们有五个参数θ0到θ4，通过给定的五个训练样本，我们可以得到如右图的拟合曲线。从该曲线来看，一方面，似乎对训练数据做了一个很好的拟合，因为这条曲线通过了所有的训练样本。但是，这实际上是一条很扭曲的曲线，它不停上下波动。事实上它并不是一个预测房价的好模型。把这类情况叫做过**拟合(overfitting)**，也叫**高方差(high variance)**。

- 结论：

	　　在拟合过程中，使用一个高阶多项式进行拟合，这个函数能很好的拟合训练集（能拟合几乎所有的训练数据），但这也就面临函数可能太过庞大的问题，变量太多。同时如果缺乏足够的数据集（训练集）去约束这个变量过多的模型，那么就会发生过拟合。


	　　过度拟合的问题通常发生在变量（特征）过多的时候。这种情况下训练出的方程总是能很好的拟合训练数据，也就是说，我们的代价函数可能非常接近于 0 或者就为 0。但是，这样的曲线千方百计的去拟合训练数据，这样会导致它无法泛化到新的数据样本中，以至于无法预测新样本价格。在这里，术语"泛化"指的是一个假设模型能够应用到新样本的能力。新样本数据是指没有出现在训练集中的数据。

- 问题提出：

	一般而言，过多的特征（变量），同时只有非常少的训练数据，会导致过度拟合的问题，为了解决过拟合问题，有一下两个方法：

	- 减少特征的维度
		- 1.人工特征选择
	
		- 2.模式选择算法）

	- 正则化
		- 1.保留所有的特征，但是会减小特征变量的数量级（参数数值的大小θ(j)

		- 2.这个方法很有效，当很多特征时，每一个特征都对预测y产生影响）

## 正则化


### 代价函数


### 正则化项


### 正则线性回归


### 正则逻辑回归



参考资料：[机器学习之正则化](http://www.cnblogs.com/jianxinzhou/p/4083921.html)