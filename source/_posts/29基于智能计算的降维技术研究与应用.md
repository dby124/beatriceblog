---
title: 基于智能计算的降维技术研究与应用
date: 2017-09-07 10:42:08
tags: [特征降维]
categories: [科研]
---
《基于智能计算的降维技术研究与应用》皋军著（2013）

# 前言

<<<<<<< HEAD
- 特征降维的需求

　　随着社会信息化的发展，在具体的只能识别过程中需要处理的数据越来越多地呈现出高位特征，比如图像处理、文本分类、视频检索、计算机视觉、微阵列数据基因选择和基于生物特征的身份识别等。造成这种现象的主要原因在于：**在智能识别过程中，只有当样本已经包含了足够多的模式分类信息时，才能得到较好的智能识别效果。然而，如何确定特征中是否已经包含了足够多的类别信号本身就是一个很难解决的问题**。因此为了提高模式识别的效果，在通常情况下，人们通常采集尽可能多的特征去提现样本的类别信息，这导致原始样本空间的维数可能达到几千维甚至上万维，而如果在如此高维的原始空间直接使用模式识别方法，那么所得到的只能识别效果将受到较大的影响。这是因为**在如此高维的特征中存在大量的冗余特征，使得特征之间的相关性较强，从而增加了模式分类算法的负担，降低了算法的效率。同时，由于随着样本特征维数的增加，使得对样本的统计特性更加难以估计，从而会影响分类算法的泛化能力，呈现所谓的过学习的现象**。

- 面临的问题和挑战

　　目前，特征降维技术作为一种关键的数据预处理技术被广泛加一研究，并在不同的实际应用领域得到了较为成功的应用，但随着新理论和新技术的不断发展，特别是大量新兴的只能识别应用领域的需求，对特征降维技术提出了更高的要求，使得现有的特征降维技术面临了更大的挑战。比如：
	
　　1）如何提高基于支持向量机的特征选择方法的泛化能力和鲁棒性；

　　2）如何更好地实现特征提取技术与**模糊聚类技术**的有机结合，以提高特征降维方法的鲁棒性；

　　3）如何提高特征降维方法中的**距离度量学习**的有效性；

　　4）如何将特征降维方法中的关键技术和理论运用到支持向量机中，以提高支持向量机的泛化能力和鲁棒性；

　　5）如何结合**张量理论**提高特征降维的效果；

　　6）如何在具有明显不同分布的源域和目标域实现提取技术等。

# 第一章 绪论
　　特征降维的方法在过去的几十年中呗广泛地加一研究，但总体上可以将已有的方法分为两大类，即特征选择（Feature Select）和特征提取（Feature Extraction）。

-  特征选择技术

	- 定义：***特征选择*是在原始的特征集中选取最有代表性的特征子集，重新构造一低维的样本空间。显而易见**，最直观的特征选择就是枚举法，通过遍历原始特征集，从所有的特征子集中寻找出最有利于只能识别的特征子集，得到全局最优解。从这一层面上来讲，枚举法更适用于低维的原始样本空间，而在处理具有高维特征的数据时，枚举法将消耗大量的时间和空间资源，甚至在可计算状态下并不能获得全局最优。

	- 近几年来，具有时间和空间复杂度低、局部最优解或次优解特点的特征选择方法被大量地提出，比如：
		- **基于支持向量机（SVM）的特征选择方法**[2-5]：一般依赖结构风险最小化原理，具有较强的泛化能力。在特征选择问题上较于基于经验风险最小的众多方法具有更好的鲁棒性。
			- 支持向量机的回归特征消除法（the SVM　Recurisive Feature Elimination,SVM-RFE），时间复杂度与样本特征数目成正比。

			- 势支持向量机（Potential Support Vector Machine，P-SVM），通过定义新的木匾函数和相应的边界条直接选取支持特征，从而提高特征选择的效率。同时由于定义了新的边界条件，在一定程度上减小了边缘误差的传播。

		- 基于概率密度估计的特征选择方法[6-7]

		- 基于信息论的特征选择方法[8-10]

		- **基于特征加权的特征选择方法**[11-13]：通过对每一特征赋予相应的权值来表征不同特征对模式分类的贡献大小。
			- 加权K-均值类型聚类（Weighting in K-Means Type Clustering，W-K——Means），通过无监督的模式分类（聚类）来得到每个特征所对应的权值，并对相应的权值进行排序，使用聚类的有效性来作为特征选择的标准。

			- RELIEF特征选择方法，根据识别相邻模式的区分能力来迭代产生相应特征的权值，算法简单有效。

			- I-RELIEF，依据最大期望原理重新构造迭代目标函数，提出新的迭代RELIEF算法，该方法在一定程度上继承了RELIEF的有点，同时可以实现多类模型分类的特征选择，提高算法的适应性。

		> 这些特征选择方法根据各自不同的评测标准来实现特征选择，而一般来说基于支持向量机、基于特征加权的特征选择方法相对于其他的方法较为直观和简单。

-  特征提取技术(也叫特征变换)
	- 定义：对原始特征空间采用采用某种具体的变换映射操作，已获取低维的投影空间。总体山更可分为线性方法和非线性方法。
	
	- 特征提取方法：
		- 线性方法
			- 基于主成分分析（PCA）：无监督方法，以方差大小作为衡量信息量大小来作为衡量信息量多少的标准，实现特征提取。
			- 线性判别分析（LDA）：有监督方法，在充分使用一直训练样本类别信息的前提下，通过构造所谓的类内散度和类间散度，并极大化类间散度和类内散度的冠以Rayleigh熵，以得到类间最大，类内最小的特征投影矢量，实现特征提取。该方法物理意义明确、几何意义直观，然而存在小样本问题（处理高维小样本数据时，类内散度矩阵容易发生异变）。
		- 非线性方法
			- 核方法（KPCA、KLDA、LPP）

			- 流形


---

# 第二章 广义的势支持特征选择方法

# 第三章 具有特征排序功能的鲁棒性模糊聚类

---

<!-- 分别讨论四种新颖的特征提取方法 -->

# 第四章基于语境距离测量的拉普拉斯最大间距判决准则

# 第五章 基于模糊最大散度差判别准则的聚类方法

# 第六章 具有模糊聚类功能的双向二维监督特征提取方法

# 第七章 基于局部加权均值的领域适应学习框架

---

<!-- 研究讨论两种基于类内散度的支持向量机的方法 -->

# 第八章 基于矩阵模式的最小类内散度支持向量机


=======
- 特征降维的需求

　　随着社会信息化的发展，在具体的只能识别过程中需要处理的数据越来越多地呈现出高位特征，比如图像处理、文本分类、视频检索、计算机视觉、微阵列数据基因选择和基于生物特征的身份识别等。造成这种现象的主要原因在于：**在智能识别过程中，只有当样本已经包含了足够多的模式分类信息时，才能得到较好的智能识别效果。然而，如何确定特征中是否已经包含了足够多的类别信号本身就是一个很难解决的问题**。因此为了提高模式识别的效果，在通常情况下，人们通常采集尽可能多的特征去提现样本的类别信息，这导致原始样本空间的维数可能达到几千维甚至上万维，而如果在如此高维的原始空间直接使用模式识别方法，那么所得到的只能识别效果将受到较大的影响。这是因为**在如此高维的特征中存在大量的冗余特征，使得特征之间的相关性较强，从而增加了模式分类算法的负担，降低了算法的效率。同时，由于随着样本特征维数的增加，使得对样本的统计特性更加难以估计，从而会影响分类算法的泛化能力，呈现所谓的过学习的现象**。

- 面临的问题和挑战

　　目前，特征降维技术作为一种关键的数据预处理技术被广泛加一研究，并在不同的实际应用领域得到了较为成功的应用，但随着新理论和新技术的不断发展，特别是大量新兴的只能识别应用领域的需求，对特征降维技术提出了更高的要求，使得现有的特征降维技术面临了更大的挑战。比如：
	
　　1）如何提高基于支持向量机的特征选择方法的泛化能力和鲁棒性；

　　2）如何更好地实现特征提取技术与**模糊聚类技术**的有机结合，以提高特征降维方法的鲁棒性；

　　3）如何提高特征降维方法中的**距离度量学习**的有效性；

　　4）如何将特征降维方法中的关键技术和理论运用到支持向量机中，以提高支持向量机的泛化能力和鲁棒性；

　　5）如何结合**张量理论**提高特征降维的效果；

　　6）如何在具有明显不同分布的源域和目标域实现提取技术等。

# 第一章 绪论
　　特征降维的方法在过去的几十年中呗广泛地加一研究，但总体上可以将已有的方法分为两大类，即特征选择（Feature Select）和特征提取（Feature Extraction）。

-  特征选择技术

	- 定义：***特征选择*是在原始的特征集中选取最有代表性的特征子集，重新构造一低维的样本空间。显而易见**，最直观的特征选择就是枚举法，通过遍历原始特征集，从所有的特征子集中寻找出最有利于只能识别的特征子集，得到全局最优解。从这一层面上来讲，枚举法更适用于低维的原始样本空间，而在处理具有高维特征的数据时，枚举法将消耗大量的时间和空间资源，甚至在可计算状态下并不能获得全局最优。

	- 近几年来，具有时间和空间复杂度低、局部最优解或次优解特点的特征选择方法被大量地提出，比如：
		- **基于支持向量机（SVM）的特征选择方法**[2-5]：一般依赖结构风险最小化原理，具有较强的泛化能力。在特征选择问题上较于基于经验风险最小的众多方法具有更好的鲁棒性。
			- 支持向量机的回归特征消除法（the SVM　Recurisive Feature Elimination,SVM-RFE），时间复杂度与样本特征数目成正比。

			- 势支持向量机（Potential Support Vector Machine，P-SVM），通过定义新的木匾函数和相应的边界条直接选取支持特征，从而提高特征选择的效率。同时由于定义了新的边界条件，在一定程度上减小了边缘误差的传播。

		- 基于概率密度估计的特征选择方法[6-7]

		- 基于信息论的特征选择方法[8-10]

		- **基于特征加权的特征选择方法**[11-13]：通过对每一特征赋予相应的权值来表征不同特征对模式分类的贡献大小。
			- 加权K-均值类型聚类（Weighting in K-Means Type Clustering，W-K——Means），通过无监督的模式分类（聚类）来得到每个特征所对应的权值，并对相应的权值进行排序，使用聚类的有效性来作为特征选择的标准。

			- RELIEF特征选择方法，根据识别相邻模式的区分能力来迭代产生相应特征的权值，算法简单有效。

			- I-RELIEF，依据最大期望原理重新构造迭代目标函数，提出新的迭代RELIEF算法，该方法在一定程度上继承了RELIEF的有点，同时可以实现多类模型分类的特征选择，提高算法的适应性。

		> 这些特征选择方法根据各自不同的评测标准来实现特征选择，而一般来说基于支持向量机、基于特征加权的特征选择方法相对于其他的方法较为直观和简单。

-  特征提取技术(也叫特征变换)
	- 定义：对原始特征空间采用采用某种具体的变换映射操作，已获取低维的投影空间。总体山更可分为线性方法和非线性方法。
	
	- 特征提取方法：
		- 线性方法
			- 基于主成分分析（PCA）：无监督方法，以方差大小作为衡量信息量大小来作为衡量信息量多少的标准，实现特征提取。
			- 线性判别分析（LDA）：有监督方法，在充分使用一直训练样本类别信息的前提下，通过构造所谓的类内散度和类间散度，并极大化类间散度和类内散度的冠以Rayleigh熵，以得到类间最大，类内最小的特征投影矢量，实现特征提取。该方法物理意义明确、几何意义直观，然而存在小样本问题（处理高维小样本数据时，类内散度矩阵容易发生异变）。
		- 非线性方法
			- 核方法（KPCA、KLDA、LPP）

			- 流形


---

# 第二章 广义的势支持特征选择方法

# 第三章 具有特征排序功能的鲁棒性模糊聚类

---

<!-- 分别讨论四种新颖的特征提取方法 -->

# 第四章基于语境距离测量的拉普拉斯最大间距判决准则

# 第五章 基于模糊最大散度差判别准则的聚类方法

# 第六章 具有模糊聚类功能的双向二维监督特征提取方法

# 第七章 基于局部加权均值的领域适应学习框架

---

<!-- 研究讨论两种基于类内散度的支持向量机的方法 -->

# 第八章 基于矩阵模式的最小类内散度支持向量机


>>>>>>> 93b7cb8a0a49d9f6481de53a40ac647fe2c08a05
# 第九章 基于全局和局部保持的半监督支持向量机