---
title: 机器学习笔记
date: 2018-2-28 15:36:53
tags: [机器学习]
categories: [机器学习]
---

来自李宏毅的Deep Learning Tutorial（PPT）的学习笔记，主要理解深度学习的概念以及工作原理等。

#  Introduction of Deep Learning

## 深度学习简介

首先介绍机器学习，机器学习相当于就是需找一个映射函数，将输入数据映射到具体的某个信息标签，如下图所示：

![function_of_machine_learning](/images/function_of_machine_learning.png)

深度学习的框架大概分为三步，如下图所示。

- step1：参数初始化，对于确定的神经网络结构，给定一组初始的权值。
- step2：对神经网络（模型）进行训练，得到一个性能较好的模型，这个模型的结构与确定的参数就构成了一个映射函数。
- step3：应用这个函数映射。

	![framework_DNN](/images/framework_DNN.png)

## DNN——全连接前馈网络

- 神经元

	![neuron](/images/neuron.png)
	
	> 每个神经元可有不同的**权重和偏置**（用参数θ表示），这就是不同神经元的差异。

- 网络结构

	![fully_connect_feedforward_network](/images/fully_connect_feedforward_network.png)

	> 不同的网络连接方式产生不同的网络结构。

全连接前馈网络，一个神经元的θ的确定，相当于确定一个映射函数，而网络结构的确定，相当于确定了一系列的函数，也即是确定了模型。

### FAQ隐含层数的如何确定？每一层的节点数目如何确定？网络结构是否是自动确定的？

　　毫无疑问，参数越多，网络的性能越好。对于一层隐含层的神经网络，只要给定足够的神经元，就是实现任意的连续函数的映射。那为什么要使用深度神经网络（多层隐含层，Thin+Tall），而不是一个较胖的神经网络（一个隐含层很多个神经元,Fat+Short）。

- `Fat+Short` vs `Thin+Tall`:根据实验`Thin+Tall`优于`Thin+Tall`。


- 训练模型的目的：得到性能好的模型，即使得模型具有较准确地将输入映射到目标输出。好的映射应当确保样本的误差尽可能的小，即对于给定的网络参数，使网络输出尽可能接近目标输出。

- 在给定的初始参数基础上，如何通过训练得到最优网络参数，从而是误差最小？

	- 梯度下降法（Gradient Descent）：由于DNN是高度非线性函数，采用BP算法训练网络容易陷入局部最优。
	> 因此，梯度下降不能保证误差全局最小。那么如何避免局部最小的问题？有以下几个方法：
	> - 随机取初始的网络参数。
	> - 受限波尔兹曼机（RBM），提供一种无监督的方法做预训练（pre-train）。
	> - 自编码器（auto encoder,AE），预训练。


#  Tips for Training Deep Neural Network

#  Variants of Neural Network（神经网络的改进）

# Next Wave

