---
title: DCASE 2017声场分类任务描述——数据集及基线系统
date: 2017-09-10 20:04:42
tags: [DCASE]
categories: [科研]
---

# 前言

　　DCASE 2017继续通过比较使用公共可用数据集的不同方法来支持计算场景和事件分析方法的开发。

　　声音带有大量有关我们日常环境和身体事件的信息。我们可以感受到我们所在的声音场景（繁忙的街道，办公室等），并且识别出各种声源（汽车通过，脚步声等）。开发用于自动提取信息的信号处理方法在多个应用中具有巨大的潜力，例如基于其音频内容搜索多媒体，使上下文感知移动设备，机器人，汽车等以及智能监控系统识别其环境中的活动使用声学信息。然而，仍然需要大量的研究来可靠地识别现实声音中的声音场景和个体声源，其中多个声音通常同时存在并被环境扭曲。

# 音频场景识别概述

　　音频场景识别的目标：将测试记录（输入）分类为所提供的预定义类别之一，其描述了记录环境的一个环境，例如“park”，“home”，“office”。

![task1_overview](/images/task1_overview.png)

# 音频数据集
　　TUT声学场景2017数据集将用作任务的开发数据。数据集由来自各种声场的记录组成，具有不同的记录位置。 对于每个记录位置，捕获了3-5分钟的长音频记录。 然后将原始记录分割成长度为10秒的段。 这些音频段在单独的文件中提供。

-  声场任务（15）：
	- 公共汽车 - 乘汽车在城市（车辆）
	- 咖啡厅/餐厅 - 小咖啡厅/餐厅（室内）
	- 汽车驾驶或作为乘客旅行，在城市（车辆）
	- 市中心（室外）
	- 森林小径（户外）
	- 杂货店 - 中型杂货店（室内）
	- 家（室内）
	- 湖畔沙滩（室外）
	- 图书馆（室内）
	- 地铁站（室内）
	- 办公室 - 多人，典型工作日（室内）
	- 住宅区（室外）
	- 火车（行车，车辆）
	- 电车（行车，车辆）
	- 城市公园（室外）
	> 详细的数据集描述见[DCASE 2016 任务1页面](http://www.cs.tut.fi/sgn/arg/dcase2016/acoustic-scenes)

-  数据集说明
	- 该数据集于2015年6月至2017年1月期间由坦佩雷理工大学在芬兰收集。数据收集已获得欧洲研究理事会的资助。
	- 记录和注释程序
	对于所有的声场，记录被捕获在不同的位置：不同的街道，不同的公园，不同的家园。录音使用Soundman OKM II Klassik /演播室A3，驻极体双耳麦克风和使用44.1 kHz采样率和24位分辨率的Roland Edirol R-09波形录音机进行。麦克风专门用于看起来像戴耳机的耳机。因此，记录的音频与到达佩戴设备的人的人体听觉系统的声音非常相似。
	
	- 记录数据的后处理涉及与记录个人隐私有关的方面。对于在私人场所录制的音像材料，所有相关人员均获得书面同意。记录在公共场所的材料不需要同意，但内容被筛选，隐私侵权细分被淘汰。麦克风故障和音频失真被注释，并且注释被提供有数据。基于DCASE 2016的实验，消除训练中的误差区域不会影响最终的分类精度。评估集不包含任何此类音频错误。

-  下载
	- 如果您使用提供的[基线系统]((https://github.com/TUT-ARG/DCASE2017-baseline-system))，则不需要下载数据集，因为系统将自动为您下载所需的数据集。

	- 开发数据集:[https://zenodo.org/record/400515](https://zenodo.org/record/400515)。或者使用[单独文件方式](http://www.cs.tut.fi/sgn/arg/dcase2017/challenge/task-acoustic-scene-classification)分别下载

-  任务设置

	- TUT声场2017数据集由两个子集组成：开发数据集和评估数据集。开发数据集由完整的TUT Acoustic Scenes 2016数据集（2016年挑战的开发和评估数据）组成。将数据划分为子集是基于原始记录的位置完成的，因此评估数据集包含类似音频场景的记录，但是来自不同的地理位置。从相同原始记录获得的所有段都包含在单个子集中 - 开发数据集或评估数据集。对于每个声场，开发数据集中有312段（52分钟的音频）。[有关数据记录和注释程序的详细说明](http://www.cs.tut.fi/~mesaros/pubs/mesaros_eusipco2016-dcase.pdf)。

	- 开发数据集：为开发数据集提供了交叉验证设置，以使结果报告与此数据集统一。该设置由四个折叠组成，根据位置分配可用段。折叠在目录评估设置中提供数据集。所提供的设置的折叠1通过使用2016开发集作为训练子集和2016评估集作为测试子集来再现DCASE 2016挑战设置。
	> 重要提示：如果您没有使用提供的交叉验证设置，请注意从相同原始录制中提取的段。确保对于每个给定的折叠，来自相同位置的所有段必须在测试子集中的训练子集OR中。

	- 评估数据集:没有实质的评估数据集将在提交截止日期前一个月公布。完整的实地元数据将在DCASE 2017挑战和研讨会结束后公布。

-  评估

	- 声场分类的得分将基于**分类精度**：正确分类的段数占总段数的比例。每个段被认为是独立的测试样本。评估在基线系统中自动完成。使用**sed_eval toolbox**进行评估。

# [**基线系统**](https://github.com/TUT-ARG/DCASE2017-baseline-system)

　　基线系统旨在实现声场分类的基本方法，并在开发系统时为参与者提供一些比较点。所有任务的基准系统共享代码库，为所有任务实现非常相似的方法。当使用默认参数运行时，**基准系统将下载所需的数据集并生成下面的结果**。

　　基线系统基于使用**对数梅尔带能量**作为特征的多层感知器架构。使用5帧上下文，导致特征向量长度为​​200。使用这些特征，一个神经网络包含两层致密的50层隐藏单元和20%个辍学(dropout)单元，训练了200次。分类决策是基于**softmax类型**的网络输出层。基准系统文档中提供了详细的描述。基准系统包括使用精度作为度量的结果评估。

　　基线系统使用**Python**（2.7和3.6版）实现。**允许参与者在给定的基准系统之上构建系统**。该系统具有数据集处理，存储/访问特征和模型所需的所有功能，并且对结果进行评估，使自己的需求更加容易。基线系统也是入门级研究人员的良好起点。

![ResultsforTUTAcousticscenes2017](/images/ResultsforTUTAcousticscenes2017.jpg)

> 运行基线系统的运行结果

- [基线系统指导手册和教程](https://tut-arg.github.io/DCASE2017-baseline-system/)


##  基线系统介绍
-  基准系统旨在降低参与DCASE挑战的障碍。它提供了一个简单的入门级方法，但是与现有技术系统相对较接近，为所有任务提供合理的性能。高端的表现让参与者找到挑战。

-  在基线中，使用特定于应用程序的扩展，可以在任务间共享一个单一的低级方法。其主要思想是展示任务设置中的并行性，以及在系统开发过程中如何轻松地在任务之间跳转。

-  主要基准系统实施以下方法：

	- 声学特征：在40ms窗口中提取具有20ms跳跃尺寸的熔融能量。

	- 机器学习：使用多层感知器（MLP）类型网络的神经网络方法（每层有50个神经元的2层，层间差异20％）。

	- 除此之外，还包括基于高斯混合模型的系统进行比较。

- 该系统是为Python 2.7和Python 3.6开发的，它可以在**Linux，Windows和Mac平台上**使用。

## 系统框图：
	
![system_approach](/images/system_approach.svg)

## 基于多感知机的系统，DCASE 2017基线系统

- 说明：选择基于多感知器的系统作为DCASE2017的基准系统。该系统的主要结构与现有的基于循环神经网络（RNN）和卷积神经网络（CNN）的现有技术系统相近，为进一步开发提供了良好的起点。该系统是围绕Keras实现的，这是一个用Python编写的高级神经网络API。Keras在多个计算后端之间工作，其中选择了Theano作为该系统。

- 系统细节：

	- 声学特征：在具有20ms跳跃尺寸的40ms窗口中提取对数梅尔带能量。
	- 机器学习：使用多层感知器（MLP）类型网络的神经网络方法（2层，每层有50个神经元，层间差异20％）。
	- 系统参数

	![Systemhyperparameters](/images/Systemhyperparameters.jpg)

## 基于GMM的方法

-  基于高斯混合模型的辅助（secondary）系统也包括在基线系统中，以便与文献中提出的传统系统进行比较。基于GMM的系统的实现非常类似于DCASE2016挑战任务1和任务3中使用的基准系统。有关DCASE2016所用系统的更多详细信息：

	[Annamaria Mesaros, Toni Heittola, and Tuomas Virtanen, “TUT database for acoustic scene classification and sound event detection”. In 24th European Signal Processing Conference 2016 (EUSIPCO 2016). Budapest, Hungary, 2016.](http://www.cs.tut.fi/~mesaros/pubs/mesaros_eusipco2016-dcase.pdf)。

-  系统细节：

　　声学特征：20个MFCC静态系数（包括第0个）+ 20个增量MFCC系数（一阶导数）+ 20个加速度MFCC系数（二阶导数）= 60个值，在具有50％跳跃尺寸的40ms分析窗口中计算。
　　机器学习：高斯混合模型，每类模型16个高斯（16 Gaussians per class model）。

-  系统参数
	
	![GMMbasedapproachSystemhyperparameters](/images/GMMbasedapproachSystemhyperparameters.jpg)

-  流程图
  
	![system_processing_blocks](/images/system_processing_blocks.svg)

	详见[网页中关于框图的详细介绍](https://tut-arg.github.io/DCASE2017-baseline-system/system_description.html#processing-blocks)

-  应用

	- 文件分类的平均准确度。

|               |  Overall      | Folds   |			|		  |		 |
| ------------- |:-------------:|:-------:|:-------:|:-------:|-----:|
|     system    |    Accuracy   |    1    |     2   |    3    |  4   |
|基于多感知机系统，2017年基线 | 74.8%   |  75.2% | 75.3% | 77.3% |  71.3% |
| 基于GMM 系统   | 74.1%         |  74.0%  |  76.0%  |  73.1%  |  73.2% |

　　 场景分类结果

![senceClassifiedResult](/images/senceClassifiedResult.jpg)

-  安装([下载地址](https://github.com/TUT-ARG/DCASE2017-baseline-system/archive/master.zip))

　　该系统是为Python 2.7，Python 3.5和Python 3.6开发的。 该系统经过测试，可在Linux，Windows和MacOS平台上工作。可以安装[官方CPython](https://www.python.org/)或使用一些基于它的[Python发行版](https://www.continuum.io/)。 推荐使用新用户使用Anaconda Python发行版。

　　**在Windows上使用系统**：基线系统使用相当长的目录路径，因为它将系统参数的32个字符的MD5哈希存储到目录名中。 某些Windows系统具有路径长度限制（最低260个字符），这是导致问题的。 为了避免与此相关的问题，请将系统尽可能靠近驱动器根目录安装。